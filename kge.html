<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KGE</title>
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="kge.css">
    <style>
        body {
            padding: 2rem;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        h1 { color: #2c3e50; margin-bottom: 0.25rem}
        h2 { color: #2c3e50; padding: 2rem 3rem 0; font-size: 2rem; margin-bottom: 0rem;}
        h3 { color: #2c3e50; padding: 2rem 3rem 0; font-size: 1.5rem; margin-bottom: 0rem;}
    </style>
</head>
<body>
    <h1>Knowledge graph embedding (KGE) for investigating proteins-proteins interactions network environment.</h1>
    <h2> Workflow :</h2>
    <p><strong>1. Data Harvest</strong><br>
     Scraped 12 M+ co-mentioned protein pairs from STRING to build a living map of the interactome.</p>

    <p><strong>2. Clean and structure dataset</strong><br>
        Filtered, deduplicated and cast the data into (head, relation, tail) triplets - clean fuel for embedding.</p>

    <p><strong>3. Tokenization, embedding and training</strong><br>
        The proteins are tokenized embedded and trained on a TransE model until every protein occupies a unique position in latent space where
        <code>h + r ≈ t</code> holds for true interactions.</p>

    <p><strong>4. Results (extracting the latent space)</strong><br>
        Exported the tuned embeddings: clustered them to reveal functional neighbourhoods, classified
        candidates, and performed nearest-neighbour walks to predict de-novo PPIs or resurrect missing edges.</p>

    <p><strong>5. Single-cell Horizon</strong><br>
        Next: overlay single-cell expression vectors to condition-specifically re-weight the manifold
        and surface PPI communities that appear only in disease or developmental states.</p>
    
    <h2>Preliminaries :</h2>

    <p>The <strong>purpose</strong> of this work is to regain knowledge in graph networks applicable to biological interactions. 
        PPI appears to be a humble start with remarkable results that can be merged with single-cell data based on expresion levels. 
        This makes it possible to see which cells are expressed in which condition and also understand their 
        neighborhoods based on their levels of expressions. This is a novel approach!</p>

    <h3>Brief introduction to Knowledge Graph Embedding</h3>
    <p>Broadly, Knowledge graphs models are powerful machine learning tools for representing and organizing complex biomedical data.
         They empower researchers, physicians, and scientists by facilitating rapid access to biomedical information, enabling the 
         discernment of patterns or insights, and fostering the formulation of decisions, the generation of novel knowledge
        and or the optimisation of results (Gema et al., 2024)</p>

    <p class="spacing-md"></p> 

    <p>In KGs, Knowledge is modelled from relationships accross entities. Fig 1. (left) shows an example application of 
        knowlege graph in a biosphere and the figure to the right summarises the pipeline (Nunes et al., 2023)</p>
    
    <div class="dual-image-container">
        <div class="image-card">
            <img src="images/kge-intro.png" class="responsive-image" alt="KG Introduction">
        </div>
        <div class="image-card">
            <img src="images/kge-method.png" class="responsive-image" alt="KG Method">
        </div>
    </div>

    <p><strong>Fig 1.</strong> (left) Relationships knowledge representation, (rigth) Example pipeline. printed from Nunes et al.</p>

    <p class="spacing-md"></p> 

    <p>The knowledge is based on vast amount of data coming from literature and curated or not databases, this data can be 
        structured to predict semantic relationships between elements. It's like taking a fish 
        in the alantic ocean and finding it's sister fish in the pacific ocean. This are semantic 
        connections that can easily be predicted by KGEs. Below is a list of databases that contain 
        curated and non curated biological dataset that can be exploited for research or clinical benefits.</p>

    <div class="centered-image">
        <img src="images/db.png" alt="Database Method" class="elegant-image">
    </div>

    <p><strong>Fig 2.</strong> Available databases containing curated and non curated bio-information for knowledge generataion.</p>

    <p class="spacing-md"></p> 

    <p> 
        Given a collection of triples (or facts) 
        <code>F = {head, relation, tail}</code>
        the knowledge graph embedding model produces, 
        for each entity and relation present in the knowledge graph a continuous vector representation.
        <code>(h, r, t)</code> is the corresponding embedding of a triple with <code>h, t ∈ ℝ<sup>d</sup> and r ∈ ℝ<sup>k</sup></code>
        where <code>d</code> is the embedding dimension for the entities, and <code>k</code> for the relations.
        The score function of a given model is denoted by <code>f<sub>r</sub>(h, t)</code> and measures the distance of the embedding 
        of the head from the embedding of tail given the embedding of the relation. In other words, it quantifies the plausibility of 
        the embedded representation of a given fact.
    </p>

    <p class="spacing-md"></p> 

    <p><strong>Knowledge graph embedding models</strong> can be categorized based on their mathematical foundations: 
        tensor decomposition models (e.g., RESCAL, TuckER), geometric models (e.g., TransE, RotatE), 
        and deep learning models (e.g., ConvE, CapsE). 
        <strong>Tensor Decomposition Models</strong> represents knowledge graphs as 3D tensors and apply factorization 
        techniques. They can take the form of a binary or non binary tensors. <strong>Geometric Models model</strong> 
        relations as geometric transformations in vector spaces. <strong>Deep Learning Models</strong> use neural 
        networks to learn complex, non-linear interaction patterns. (A. Rossi et al., 2021).
    </p>

    <div class="centered-image">
        <img src="images/model1.png" alt="models" class="elegant-image">
    </div>

    <p><strong>Fig 3.</strong> KGE models from literature. Printed from Rosi et al.</p>

    <p class="spacing-md"></p> 

    <p><strong>Performance indicators</strong> are used to measure the quality of embedding models. Given Q as the set of
        all ranked predictions of a model, it is possible to define three different performance indexes:
        Hits@K, MR, and MRR. (Z. Chen et al., 2020)</p>

    <p style="padding-left: 20px;"><strong>Hits@K</strong> or in short, H@K, is a performance index that measures the probability to find the correct 
        prediction in the first top K model predictions. Usually, it is used <code>k = 10</code>. Hits@K 
        reflects the accuracy of an embedding model to predict the relation between two given triples 
        correctly</p>

    <p style="padding-left: 20px;"><strong>Mean rank</strong> is the average ranking position of the items predicted by the model among all the 
        possible items.</p>

    <p style="padding-left: 20px;"><strong>Mean reciprocal rank</strong> measures the number of triples predicted correctly. If the first predicted 
        triple is correct, then 1 is added, if the second is correct 1/2 is summed, and so on. Mean 
        reciprocal rank is generally used to quantify the effect of search algorithms. The larger the index, 
        the better the model.</p>

    <h2>KGE for PPI network</h2>
    <h3>(1) Harvesting Data</h3>
    <p>String contains a vast amount of protein-protein interaction network. I downloaded 10090.protein.links.full.v12.0.txt (mouse)
        provides confidence-scored interactions derived from multiple evidence sources including experimental data, text mining, 
        and computational predictions. The text file contains 12684355 proteins links of known proteins in contact with other proteins. 
        We can not tell what they do but they are known to have physical contact with other proteins. 
    </p>

    <h3>(2) Cleaning and structuring</h2>
    <p>Each interaction was structured as a triple (head, relation, tail), where head and tail entities represent interacting proteins, 
        and the relation type is determined based on the combined score (score from sources - text mining, databases, transfered experiments). 
        This data creates only a mono-relational knowledge graph because information only represents physical contact observation.</p>

    <p class="spacing-md"></p> 

    <p>This transformation from pairwise interactions to formal (h, r, t) triples enables the application of knowledge graph which
        embeds this relationship in space and calculates the similarity distances between each elements. similarity matrix represents knowledge 
        in space. Based on this mechanisms, relational semanticness can be captured  beyond simple binary associations. By distinguishing relation 
        types based on evidence sources, the resulting knowledge graph preserves the biological context of interactions, 
        allowing models to learn differentiated representations for experimentally-verified versus computationally-predicted relationships. 
        This structured format facilitates downstream tasks including link prediction, protein function inference, 
        and multi-relational reasoning across heterogeneous biological evidence</p>

    <h3>(3) Tokenization, embedding and training</h3>
    <p>The first step at this stage is encoding. Embedding is all about vectorization, in order to vectorize inputs must take numerical
        formats. For the simplicity of this study and the input format, Ordinal encoding was used to encode the proteins informations for embeddings.</p>

    <p class="spacing-md"></p> 

    <p>In Machine Learning, there're are many methods used to vectorized characters. I will briefly describe a few of them :</p>
    <p><strong>One hot encoding</strong> creates a vector of 0s and 1s based on the features of characters, can range for 2 bits and above. </p>
    <p><strong>Ordinal encoder</strong> maps each unique character sequence to an interget to form a vector of integers eqaul to the length of the 
        all character sequence</p>
    <p><strong>Bag of words</strong> is also called tokenizaiton where a sentence or sequence is broken down to form tokens which defines the vector
        vocabulary. Only unique words are selected to create the vocabulary and then sorted by alphabetical order. A sentence is 
        represented as a list of its constituent words, and it's done for all the input sentences.</p>
    <p><strong>TF-IDF</strong> Termed Frequency-Inverse Document Frequency, is a numerical statistic that's intended to reflect how important a word 
        is to a document. Although it's another frequency-based method, it's not as naive as Bag of Words. Because it gives attention
        to words that carries more meaning in set of sequences</p>
    <p><strong>Word2Vec</strong> In a nutshell, uses the power of a simple Neural Network to generate word embeddings. It is said to be contextually aware
        over TF-IDF</p>
    <p><strong>GloVe</strong> which stands for Global Vectors for word representation works like Word2Vec, created for contextual word embedding 
        but works on performance over Word2Vec. read more <a href="https://neptune.ai/blog/vectorization-techniques-in-nlp-guide" target="_blank">here</a></p></p>
    
    <p class="spacing-md"></p> 

    <p>The numerical characters are then embedded by pytorch embedding function which draws from a gaussian distribution to create random
        numbers at first. This random vectors or weigths are modified during learning to adjust as information is fed back into the loop.</p>
    
    <p>A TransE model is instantiated with 20-dimensional embeddings, meaning each entity and relation will be represented by a 20-element vector. 
        The Adam optimizer with a learning rate of 0.01 is configured to update all trainable parameters.
        During training, data is loaded in mini-batches of 64 triples. Positive triples are fed to the model's scoring function,
         which computes plausibility scores based on the TransE principle: score = -||h + r - t||. Negative samples are generated 
         by corrupting either the head or tail entity of each positive triple with random entities. Negative scores are computed similarly.
         In supervised neural network, the loss is calculated by taking square matrix of the predicted vs actual. Here, since the models learns by
         scoring the embedding space, the model must learn to attribute lower scores to the corrupted matrix. Finally, the model uses a 
         margin-based ranking loss which encourages positive triplets to score at least 1 unit more than the negative triplets.</p>

    <p class="spacing-md"></p> 

    <p>The TransE model is a graphical model that computes the distance between vectors in space. It is the heart of the scoring function based
        on distace matrix.</p>

    <div class="centered-image">
        <img src="images/transe.png" alt="models" class="elegant-image">
    </div>
    <p><strong>Fig 4.</strong> Translation-based Scoring Functions : Translating Embeddings (TransE). Printed from ECAI 2020</p>

    <p class="spacing-md"></p> 

    <p>The optimization mechanics is such that, gradients are zeroed to prevent accumulation. Backpropagation computes 
        gradients through the computational graph. The Adam optimizer updates all parameters, including : Entity embedding 
        matrix weights and relation embedding matrix weights.</p>
    
    <p class="spacing-md"></p>

    <p>At the end of training, entity vectors gradually position themselves <strong>such that h + r ≈ t holds for true triples</strong>,
        relation vectors capture geometric translations between entity types, the embedding space self-organizes to satisfy 
        the relational constraints present in the training data and biologically related entities naturally cluster in the 
        learned 20-dimensional space</p>

    
    <h3>(4) Results (extracting the latent space)</h3>
    <p>The embedding holds the weights that defines the attributes of the proteins-proteins interactions in a latent space (space with hidden meaning).
        This embedding can be extracted for further downstream analysis and and condrol over clusters of interest with might represent biological 
        clarity of proteins elements containing force fields of interest working together.</p>
    
    <div class="centered-image">
        <img src="images/embedding.png" alt="models" class="elegant-image">
    </div>

    <p><strong>Fig 5.</strong> Protein-protein interactons embedded in a vector space (points represents proteins, distances represents relationship strengths)</p>

    <p class="spacing-md"></p>

    <p>It is beatiful to observe some proteins with stronger relationship clustering together, weaker relationships existing further away, 
        overall forming clusters that may be investigated. In this view, I choosed four clusters randomly to examine or take a closer look
        at the elements interacting together by first looking at raw embeddings, then converting the vectors back to proteins names.</p>

    <div class="centered-image">
        <img src="images/entity_clu_raw.png" alt="models" class="elegant-image">
    </div>

    <p><strong>Fig 6.</strong> Raw embeddings of clusters of interest</p>

    <p class="spacing-md"></p>

    <p>Now I convert this raw embeddings from vectors into proteins to find the proteins involve in this clusters. Also based on the 
        literature knowledge, show the link between proteins interacting with each other. First we observe similarities based on learned weights,
        and secondly how they connect from curated information from literature. </p>

    <div class="dual-image-container">
        <div class="image-card">
            <img src="images/cluster1.png" class="responsive-image" alt="KG Introduction">
        </div>
        <div class="image-card">
            <img src="images/cluster2.png" class="responsive-image" alt="KG Method">
        </div>
    </div>
    <div class="dual-image-container">
        <div class="image-card">
            <img src="images/cluster3.png" class="responsive-image" alt="KG Introduction">
        </div>
        <div class="image-card">
            <img src="images/cluster4a.png" class="responsive-image" alt="KG Method">
        </div>
    </div>

    <p><strong>Fig 7.</strong> Extraction of clusters of interest from the embedding space and further 
        investigation. Cluster1, 2, 3 and 4 represented from left to right</p>

    <p class="spacing-md"></p>

    <p>Cluster1 and cluster 4 shows that smaller clusters exist within larger clusters. Navigating from embedding space to clusters
        of interest, it is possible to navigate to protein of interest to investigate more closely it's interactom of interest in this embedding space.
        The procedure is simular to that of prediting an unkown protein or a novel protein. Remember gene names are used in the embedding space for clarity
        (avoid using longer protein names).</p>

    <div class="centered-image">
        <img src="images/protein.png" alt="models" class="elegant-image">
    </div>

    <p><strong>Fig 8.</strong> Predicting/investigating the interactom of a protein of interest</p>

    <h3>(5) Single-cell integration</h3>
    <p>While this is amazing, modern highthroughput techniques struggle to elucidate biological meaning in situ. The completeness of KGE will come from 
        integrating it's workflow with modern methods to enhance clarity of context at the single cell resolution level. Given more time, I look forward to 
        integrate this workflow with single-cells and epigenetics workflows to provide clarity not only on expression levels but how the interactoms
        are reflected by the expression levels. This can provide more meaning to functional genomics and phylogeny. knowing the proportion
    of expressed molecules interacting with a given proportion of other molecules may help elucidate morphogenic patterns in biological systems.</p>

    <p class="spacing-md"></p>

    <p><strong>This work is designed and realised by Desmond Akabetso Nde, October 2025.</strong></p>

    <p class="spacing-md"></p>

    <h3>References</h3>
    <p>Gema, Aryo Pradipta et al. “Knowledge graph embeddings in the biomedical domain: are they useful? A look at link prediction, rule learning, and 
        downstream polypharmacy tasks.” Bioinformatics advances vol. 4,1 vbae097. 17 Jul. 2024, doi:10.1093/bioadv/vbae097</p>
    <p class="spacing-md"></p>
    <p>Nunes, Susana et al. “Multi-domain knowledge graph embeddings for gene-disease association prediction.” Journal of biomedical 
        semantics vol. 14,1 11. 14 Aug. 2023, doi:10.1186/s13326-023-00291-x</p>
    <p class="spacing-md"></p>
    <p>Rossi, Andrea, et al. "Knowledge Graph Embedding for Link Prediction: A Comparative Analysis." ACM Transactions on Knowledge Discovery 
        from Data (TKDD), vol. 15, no. 2, 4 Jan. 2021, pp. 1-49, doi.org/10.1145/3424672</p>
    <p class="spacing-md"></p>
    <p>Z. Chen, Y. Wang, B. Zhao, J. Cheng, X. Zhao and Z. Duan, "Knowledge Graph Completion: A Review," in IEEE Access, vol. 8, pp. 192435-192456, 
        2020, doi: 10.1109/ACCESS.2020.3030076.</p>
    <p class="spacing-md"></p>
    <p>https://neptune.ai/blog/vectorization-techniques-in-nlp-guide</p>
    <p class="spacing-md"></p>
    <p>https://en.wikipedia.org/wiki/Knowledge_graph_embedding#cite_note-:31-10</p>
</body>
</html>